# -*- coding: utf-8 -*-
"""product_recommender.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PsK41Vsf2JErktTWsOEft-L7SHdzoO53

# **Welcome to the notebook**

### Task 1 - Set up project environment

Installing the needed modules
"""

!pip install openai==1.16.2 python-dotenv

"""Importing the needed modules and setup the OpenAI API"""

import pandas as pd
import numpy as np
import os
from openai import OpenAI
from dotenv import load_dotenv
from matplotlib import pyplot as plt
import plotly.express as px

from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import cosine_similarity

# Loading API key and organization ID from a dotenv file
load_dotenv(dotenv_path='apikey.env.txt')

# Retrieving API key and organization ID from environment variables
APIKEY = os.getenv("APIKEY")

# Creating an instance of the OpenAI client with the provided API key and organization ID
client = OpenAI(
  api_key=APIKEY
)

client

"""Import our dataset"""

df = pd.read_csv('products_dataset.csv')
df.head()

"""List of last 8 products recently viewed by the user."""

searched_products_id = [
    'P1938',
    'P1970',
    'P1044',
    'P1838',
    'P1048',
    'P1017',
    'P1310',
    'P1444',
]

"""### Task 2 - Prepare the dataset

Let's label the data points that are recently veiwed.
"""

df['product_status'] = 'not_viewed'
df.loc[df['product_id'].isin(searched_products_id), 'product_status'] = 'recently_viewed'
df[df.product_status == 'recently_viewed']

"""Now let's combine the product `title` and `description` and store it into a column called `combined`."""

df['combined'] = df['title'] + ' ' + df['description']
df.head()

"""### Task 3 - Text embedding and visualization

Creating the text embedding vectors
"""

response = client.embeddings.create(
  model="text-embedding-3-small",
  input=df['combined'].tolist(),
  dimensions=512
)
vectors = [d.embedding for d in response.data]
df['text_embedding'] = vectors

df.head()

"""> We know that each vector has 512 dimensions. In order to be able to visualize the vectors in a scatter plot, we need to use Principal Component Analysis (PCA) to reduce the dimension from 512 to 2."""

pca = PCA(n_components=2)
pca_result = pca.fit_transform(df['text_embedding'].tolist())
pca_result

df['pca1'] = pca_result[:, 0]
df['pca2'] = pca_result[:, 1]
df.head()

"""Now that we have the text embedding vectors in two dimensions, we can use them to create a 2D plot."""

px.scatter(df, x='pca1', y='pca2', color='product_status')

"""### Task 4 - Find similar products"""

df.head()

"""Get the data related to `recently_viewed` and `not_viewed` products"""

df_recently_viewed = df[df.product_status == 'recently_viewed']
df_not_viewed = df[df.product_status == 'not_viewed']

"""Convert the embedding vectors to Numpy arrays"""

df_recently_viewed

df_not_viewed

vectors_recently_viewed = np.array(df_recently_viewed['text_embedding'].tolist())
vectors_not_viewed = np.array(df_not_viewed['text_embedding'].tolist())

vectors_not_viewed

vectors_recently_viewed

"""Find the similarity between each viewed product and all the unviewed products."""

similarity_matrix = cosine_similarity(vectors_recently_viewed, vectors_not_viewed)

similarity_matrix.shape

top_ids = []
for row in similarity_matrix:
  top_id = np.argmax(row)
  top_ids.append(top_id)

top_ids

"""### Task 5 - Recommend products based on the searched products

Let's update the status of the top similar products to `recommended`.
"""

most_similar_products = list(df_not_viewed.iloc[top_ids].product_id)

most_similar_products

"""Let's visualize the recommended products."""

df.loc[df['product_id'].isin(most_similar_products), 'product_status'] = 'recommended'
df[df.product_status == 'recommended']

px.scatter(df, x='pca1', y='pca2', color='product_status', hover_data=['product_id', 'title'])